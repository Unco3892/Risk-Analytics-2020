---
title: "report"
output: html_document
---
```{r, echo = FALSE, message = FALSE, include=FALSE}
source(here::here("scripts/setup.R"))
```

# a)

```{r}
waiting <- read.csv(here::here("data/waiting.csv"))
```
*Graph* displays the daily waiting times period that the Data covers. It is difficult to notice any seasonality or cyclic patterns in the extreme waiting times.

```{r, fig.asp=.2}
waiting %>%
  ggplot(aes(Date, Average.Wait.Seconds)) +
  geom_line() +
  geom_point()
```

As shown on *graph* and on *table*, Monday, Tuesday and Wednesday are the days of the week that present the highest extreme values. We can also notice that even if Friday has the highest average waiting time, its maximum value is the lowest.

```{r}
waiting %>%
  mutate(Weekday=factor(Weekday, levels= c("Monday", 
    "Tuesday", "Wednesday", "Thursday", "Friday"))) %>%
  group_by(Weekday) %>%
  summarize(Min = min(Average.Wait.Seconds),
             Q1 = quantile(Average.Wait.Seconds, .25),
             Avg = mean(Average.Wait.Seconds), 
             Q3 = quantile(Average.Wait.Seconds, .75),
             Max = max(Average.Wait.Seconds))
```

```{r}
waiting %>%
  mutate(Weekday=factor(Weekday, levels= c("Monday", 
    "Tuesday", "Wednesday", "Thursday", "Friday"))) %>%
  ggplot(aes(Average.Wait.Seconds, Weekday)) +
  geom_boxplot() +
  coord_flip() +
  ylab("") +
  xlab("Average waiting time (sec)")
```

# b) 

```{r}
n <- 250

p <- (1-(1/n))

mean <- mean(waiting$Average.Wait.Seconds)
sd <- sd(waiting$Average.Wait.Seconds)

upper_limit <- qnorm(p, mean, sd)
upper_limit
```

As the one year period corresponds to `n = 250`, we can deduce the upper control limit, which corresponds to `p = 1-1/n` and equals to `r p`. 
After scaling this value, we can retrieve the associated quantile or the upper control limit, which corresponds to `r upper_limit`.

*Graph* suggest that the normal distribution is not appropriate to predict extreme values, the extreme observations tend to diverge strongly from their theoretical values under the assumption of a normal distribution. This suggests that the tails are heavy.
```{r}
qqnorm(scale(waiting$Average.Wait.Seconds))
qqline(scale(waiting$Average.Wait.Seconds))
hist(waiting$Average.Wait.Seconds)
```
 
```{r}
shapiro <- shapiro.test(waiting$Average.Wait.Seconds)
```

Running the Shapiro-Wilk test shows that the hypothesis of normality is rejected at level `r shapiro$p.value`

# c) The aim of this analysis is to focus on negative effects (long wait times). Explain how you would proceed using 1) a block maxima and 2) a peaks-over-threshold approach. For each method, carry out the required data aggregation and transformation.



The Block Maxima approach divides the dataset into blocks with the same number of observations. Then, for each block we select the observation with the highest value. Looking at the dataset, we can divide the it by months, week or year:

```{r}
# To see what the block size should be
library(dplyr)
library(ggplot2)

waiting %>% 
  group_by(year(ymd(Date)), month(ymd(Date))) %>%
  head(20) %>% 
  filter(Average.Wait.Seconds == max(Average.Wait.Seconds))

test<- split(waiting, 20)

group_split(waiting, year(ymd(Date)), month(ymd(Date)), .keep = TRUE)

split(waiting, sample(1:22, nrow(waiting), replace=T))

test %>% 
  group_by(year(ymd(Date)), month(ymd(Date))) %>%
  filter(Average.Wait.Seconds == max(Average.Wait.Seconds))
# per year
tmp <- data.frame(x=rep(seq(as.Date(0, origin="2017-01-01"),
                            length=2, by="1 year"), 2))

plot_all_obs + geom_vline(xintercept=as.numeric(tmp$x),
                linetype=4, colour="red")
# remove last month withouth data
```

Looking at the data aggregation per month, week and year we conclude that the best way to break the blocks is per month. So we are going to select the maximum for each block and do our analysis on the maxima. 

```{r}
library(lubridate)

maxima <- waiting %>% 
  group_by(year(ymd(Date)), month(ymd(Date))) %>% 
  filter(Average.Wait.Seconds == max(Average.Wait.Seconds))

tmp <- data.frame(x=rep(seq(as.Date(0, origin="2017-01-01"),
                            length=36, by="1 month"), 2),
                  y=rnorm(72),
                  category=gl(2,36))

plot_all_obs + geom_vline(xintercept=as.numeric(tmp$x),
                linetype=4, colour="red")

#plot of the maxima
maxima %>% 
  ggplot(aes(x = Date, y = Average.Wait.Seconds)) +
  geom_point(color = "red")
  
```


## 2) Peaks-over-threshold approach

The Peaks-over-threshold approach defines the extreme values as the observation above a certain threshold u. In order to find this threshold, we can use an mrlplot:

```{r,message = FALSE,warning=FALSE}

# POT approach
library(extRemes)
library(xts)
library(ismev) 
library(evd)

mrlplot(waiting$Average.Wait.Seconds,umin = min(waiting$Average.Wait.Seconds), umax = max(waiting$Average.Wait.Seconds))

tlim <- c(81,1182)
tcplot(waiting$Average.Wait.Seconds, tlim = c(81,1100), std.err = FALSE)

# we take a threshold of 800 

plot_all_obs + geom_hline(yintercept=800,
                linetype=4, colour="red")



```



# d) Propose a model for the data you have processed in the previous question. Make sure to justify your model choice using residuals and goodness-of-fit tests. (Hint: you may use the evd package.)

1) Block Maxima approach
To see what kind of distribution to use, we have to estimate $\xi, $\sigma, and $\mu for the maxima. To do so, we can either do it manually, or use a library to do it.

```{r, warning = FALSE}
# fitting the GEV to the maxima in order to have the location, scale and shape parameters
library(evd)
fit_gev_maxima <- evd::fgev(maxima$Average.Wait.Seconds)
# evd_profile <- profile(gev_maxima)
# M1JP <- profile2d(fit_evd, evd_profile, which = c("scale", "shape"))
# plot(M1JP)

fit_gev_maxima

fit_gev_maxima$std.err
 #anova(object, object2, ..., half = FALSE)
```


``` {r}
library(evir)
fit_gev_maxima_evir<-gev(maxima$Average.Wait.Seconds)
fit_gev_maxima_evir
plot(fit_gev_maxima_evir, main = c("Scatterplot of Residuals", "QQplot of Residuals"), ask = FALSE)

# first scatterplot
# second QQplot

 
```



2) POT
```{r}

# fits the w = x - u to a gpd
pot_800 <-fpot(waiting$Average.Wait.Seconds, threshold = 800, model = c("gpd"))
pot_600 <-fpot(waiting$Average.Wait.Seconds, threshold = 600, model = c("gpd"))

pot_600$std.err
pot_800$std.err # higher standard error for both scale and shape parameter

par(mfrow=c(2,2))
plot(pot_600)

par(mfrow=c(2,2))
plot(pot_800)


```

```{r}
library(evir)

pot_2_600<-gpd(waiting$Average.Wait.Seconds, threshold = 600, nextremes = NA, method = c("ml"))
par(mfrow=c(2,2))
plot(pot_2_600)    


```
```{r}

pot_2_800<-gpd(waiting$Average.Wait.Seconds, threshold = 800, nextremes = NA, method = c("ml"))
par(mfrow=c(2,2))
plot(pot_2_800)    
```

# e) Finally, use your model to derive an upper control limit or confidence line for the waiting times at the one-year return level.

One year return level corresponds, in our dataset, to 250 days.

```{r}

# return level block maxima:
fit_gev_maxima$estimate

return_level_maxima <- fit_gev_maxima$estimate[1] + (fit_gev_maxima$estimate[2]/fit_gev_maxima$estimate[3])*(((-log(1-1/250))^-fit_gev_maxima$estimate[3])-1)

```