---
title: "report"
output: html_document
---

```{r, message=FALSE, warning=FALSE}
source(here::here("scripts/setup.R"))

library(reshape2)
library(copula)
```


```{r}
sales_10_adj <-
  read.csv(here::here("data/sales_10_adjusted.csv"))
```


## a)


## b)

```{r}
#CHI
nb_prod <- length(sales_10_adj)

chi <- matrix(NA, nb_prod, nb_prod)

colnames(chi) <- 1:10
rownames(chi) <- 1:10

for (i in 1:(nb_prod - 1)){
  for (j in (i + 1):nb_prod){
    chi[i,j] <- extRemes::taildep(sales_10_adj[,i], sales_10_adj[,j], 0.9)[[1]]
  }
}

longChi<-melt(chi)

longChi %>%
  filter(!is.na(value)) %>%
  ggplot(aes(x = factor(Var1), y = factor(Var2))) +
  geom_raster(aes(fill=value)) +
  scale_fill_gradient(low="grey90", high="red") +
  labs(x="product", y="product", title="chi", fill = "chi")
```


```{r}
#CHI BAR
nb_prod <- length(sales_10_adj)

chi_bar <- matrix(NA, nb_prod, nb_prod)

colnames(chi) <- 1:10
rownames(chi) <- 1:10

for (i in 1:(nb_prod - 1)){
  for (j in (i + 1):nb_prod){
    chi_bar[i,j] <- extRemes::taildep(sales_10_adj[,i], sales_10_adj[,j], 0.9)[[2]]
  }
}

longChi_bar<-melt(chi_bar)

longChi_bar %>%
  filter(!is.na(value)) %>%
  ggplot(aes(x = factor(Var1), y = factor(Var2))) +
  geom_raster(aes(fill=value)) +
  scale_fill_gradient(low="grey90", high="orange") +
  labs(x="product", y="product", title="chi bar", fill = "chi bar")
```



```{r}
nb_prod <- length(sales_10_adj)

pvalue <- matrix(NA, nb_prod, nb_prod)

for (i in 1:(nb_prod - 1)) {
  for (j in (i + 1):nb_prod) {
    pvalue[i, j] <-
      extRemes::taildep.test(sales_10_adj[, i], 
                             sales_10_adj[, j], 
                             cthresh =
                               -0.1)$p.value[[1]]
  }
}

longPval<-melt(pvalue)

longPval %>%
  filter(!is.na(value)) %>%
  arrange(desc(value)) %>%
      mutate(pvalue = case_when(
      value >= 0.05 ~ "> 5%",
      value < 0.05 ~ "< 5%")) %>%
  ggplot(aes(x = factor(Var1), y = factor(Var2))) +
  geom_raster(aes(fill=pvalue)) +
  labs(x="product", y="product", title="Tail Dependence Test", fill = "P-Value")
```

Null hypothesis is tail dependence!
Red = reject H0 = indep.

High tail dependence for extreme values :
```{r}
chiplot(cbind(sales_10_adj[,2], sales_10_adj[,3]), which = 2)
```

Low tail dependence for extreme values :
```{r}
chiplot(cbind(sales_10_adj[,2], sales_10_adj[,10]), which = 2)
```


## c)

The Gaussian copula is asymptotically independent in both upper and lower tails.
Since a majority of pairs seems dependent in upper tail, the Gaussian copula seems inappropriate.

## d)
### .i
```{r}
# Thresold : quantile @ 0.9s
thresholds <- numeric(10)

for (i in 1:10) {
  thresholds[i] <- quantile(sales_10_adj[,i], 0.9)
}

# Model for the tail : POT
fit_pot <- list()

for (i in 1:10) {
  fit_pot[[i]] <- evd::fpot(sales_10_adj[,i], thresholds[i])
}
```

```{r}
transform_to_uniform <- function(y,
                                 cdf,
                                 threshold,
                                 scale,
                                 shape) {
  
  above <- y > threshold
  # proportion of exceedances
  p <- mean(above)
  # under the threshold, use the empirical CDF
  ecdf_below <- ecdf(y[!above])
  empirical <- ecdf_below(y[!above])
  # above, apply dgpd
  theoretical <- cdf(y[above],
    loc = threshold,
    scale = scale,
    shape = shape
  )
  
  transformed <- numeric(length = length(y))
  # "Glue together" the empirical and theoretical parts by rescaling them:
  
  #        empirical          e.g. N(0,1)
  # [-----------------------|-------------]
  # 0                       p             1
  
  transformed[!above] <- (1 - p) * empirical    # (1)
  transformed[above] <- 1 - p + p * theoretical # (2)
  
  return(list(
    transformed = transformed,
    ecdf = ecdf_below,
    prop = p
  ))
}
```


```{r}
uniformised <- lapply(1:10, function (i) {
transform_to_uniform(sales_10_adj[,i], 
                     cdf = evd::dgpd, 
                     threshold = thresholds[i], 
                     scale = fit_pot[[i]]$estimate[1],
                     shape = fit_pot[[i]]$estimate[2])
  
})
```

```{r}
# merging the u's
transformed <-  as.data.frame(uniformised[[1]]$transformed)
colnames(transformed) <- "product_1"

for (i in 2:10){
  temp <- as.data.frame(uniformised[[i]]$transformed)
  colnames(temp) <- paste0("product_",i)
  transformed <- cbind(transformed, temp)
}
```

### .ii 

```{r warning=FALSE, message=FALSE}
fit_results <- expand.grid(Copula = c("Gauss", "Gumbel", "Clayton", "T"),
                       param1 = NA,
                       param2 = NA,
                       LogLikelihood = NA,
                       AIC = NA)
```



```{r warning=FALSE, message=FALSE}
fit_normal <- fitCopula(normalCopula(dim = 10), transformed, method = "ml")


fit_results$param1[1] <-coef(fit_normal)[1]
fit_results$param2[1] <-"-"
fit_results$LogLikelihood[1] <- stats::logLik(fit_normal)
fit_results$AIC[1] <- stats::AIC(fit_normal)
```

```{r warning=FALSE, message=FALSE}
fit_gumbel <- fitCopula(gumbelCopula(dim = 10), transformed, method = "ml")

fit_results$param1[2] <-coef(fit_gumbel)[1]
fit_results$param2[2] <-"-"
fit_results$LogLikelihood[2] <- stats::logLik(fit_gumbel)
fit_results$AIC[2] <- stats::AIC(fit_gumbel)
```

```{r warning=FALSE, message=FALSE}
fit_clayton <- fitCopula(claytonCopula(dim = 10), transformed, method = "ml")

fit_results$param1[3] <-coef(fit_clayton)[1]
fit_results$param2[3] <-"-"
fit_results$LogLikelihood[3] <- stats::logLik(fit_clayton)
fit_results$AIC[3] <- stats::AIC(fit_clayton)
```

```{r warning=FALSE, message=FALSE}
fit_t <- fitCopula(tCopula(dim = 10), transformed)

rho <- coef(fit_t)[1]
df <- coef(fit_t)[2]

fit_results$param1[4] <-coef(fit_t)[1]
fit_results$param2[4] <-coef(fit_t)[2]
fit_results$LogLikelihood[4] <- stats::logLik(fit_t)
fit_results$AIC[4] <- stats::AIC(fit_t)
```


```{r}
fit_results %>% arrange(AIC)
```

### .iii

```{r}
simulated <- rCopula(1913, tCopula(param = rho, dim = 10, df = df))
# simulated <- rCopula(1913, normalCopula(fit_results$param1[1], dim = 10))
# simulated <- rCopula(1913, gumbelCopula(fit_results$param1[2], dim = 10))
# simulated <- rCopula(1913, claytonCopula(fit_results$param1[3], dim = 10))
```

```{r}
inverse_transform <- function(u, ecdf, quantile_function, p, threshold, scale, shape) {
  above <- u > 1 - p
  original_scale <- numeric(length = length(u))
  original_scale[!above] <- quantile(ecdf, u[!above] / (1 - p))
  original_scale[above] <-
    quantile_function((u[above] - (1 - p)) / p, threshold, scale, shape)
  return(original_scale)
}
```

```{r}
simulated_inversed <- sapply(1:10, function (i) {
inverse_transform(u = simulated[,i], 
                  ecdf = uniformised[[i]]$ecdf,
                  quantile_function = evd::qgpd,
                  p = uniformised[[i]]$prop,
                  threshold = thresholds[i],
                  scale = fit_pot[[i]]$estimate[1],
                  shape = fit_pot[[i]]$estimate[2])
  
})
```

### iv

VaR of the sum
```{r}
#Generated + retransformed
S <- rowSums(simulated_inversed)
quantile(S, 0.95)
```


```{r}
#Original Data
quantile(rowSums(sales_10_adj), 0.95)
```

Sum of the VaR
```{r}
#Generated + retransformed
sum(apply(simulated_inversed, 2, quantile, 0.95))
```


```{r}
# original data
sum(apply(sales_10_adj, 2, quantile, 0.95))
```

<!-- ```{r} -->
<!-- fit_simulated <- evd::fpot(S, quantile(S, 0.9)) -->


<!-- u <- fit_simulated$threshold -->
<!-- p <- length(fit_simulated$exceedances)/length(S) -->


<!-- VAR <- u + fit_simulated$estimate[1]/fit_simulated$estimate[2] * (((1-0.95)/p)^-fit_simulated$estimate[2]-1) -->

<!-- VAR[[1]] -->
<!-- ``` -->


<!-- ```{r message=FALSE, warning=FALSE} -->

<!-- VaR <- numeric(10) -->

<!-- for (i in 1:10) { -->
<!-- mod <- QRM::fit.GPD(simulated_inversed[,i], threshold = quantile(simulated_inversed[,i], 0.9)) -->
<!-- VaR[i] <- QRM::RiskMeasures(mod, c(0.95))[2] -->
<!-- } -->

<!-- sum(VaR) -->
<!-- ``` -->

